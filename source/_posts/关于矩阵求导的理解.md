---
title: 关于矩阵求导的理解
date: {{ date }}
categories:
 - 机器学习杂谈
tags:
 - 机器学习
 - 矩阵求导
 - 数学
toc: true
mathjax: true
---



## 矩阵微分

> 为了书写方便，常把单个函数对多个变量或者多元函数对单个变量的偏导数写成向量或者矩阵的形式，使其可以当做一个整体处理。矩阵微积分是多元微积分的一种表达方式，即可以使用矩阵和向量来表示因变量每个成分关于自变量每个成分的偏导数。 ——《神经网络与深度学习》

对这句话的理解：

1. 矩阵微分是多元函数求导的一种书写行书，它的结果是各个偏导数的按照某一规定的布局。

2. 矩阵微分的结果是一个矩阵或者向量，它内部一定包含 **因变量里每一个成分关于自变量里每一个分量的偏导数** ，即
    $$
    \frac{\partial{\pmb{Y}}}{\partial{\pmb{X}}}=
     \left[
     \begin{matrix}
        &  &  \\
        & \frac{\partial y_i}{\partial x_j} &  \\
       &  & 
      \end{matrix}
      \right]\\
      y_i\in\pmb{Y},x_j\in\pmb{X}
    $$

3. 这里的 $\frac{\partial y_i}{\partial x_j}$ 是一个代表元素， 下标 $i$ 和 $j$ 也可以理解为在分母布局下的第 $i$ 行、第 $j$ 列 ; 在分子布局下的第 $i$ 列、第 $j$ 行，关于分子布局分母布局见下面。

<!-- more -->

> 矩阵微积分的表示通常有两种符号约定： 分子布局（ Numerator Layout）和分母布局 （ Denominator Layout）。两者的区别是一个标量关于一个向量的导数是写成列向量还是行向量 。

例：

分子布局下
$$
\pmb{X}=[x_1,...,x_n]\\
\frac{\partial{y}}{\partial{\pmb{X}}}=[
 \begin{matrix}
   \frac{\partial{y}}{\partial{}x_1},
   \frac{\partial{y}}{\partial{}x_2},
   ...,
   \frac{\partial{y}}{\partial{}x_n}
  \end{matrix}]
$$
分母布局下
$$
\pmb{X}=[x_1,...,x_n]\\
\frac{\partial{y}}{\partial{\pmb{X}}}=\left[
 \begin{matrix}
   \frac{\partial{y}}{\partial{}x_1}\\
   \frac{\partial{y}}{\partial{}x_2}\\
   .\\
   .\\
   .\\
   \frac{\partial{y}}{\partial{}x_n}\\
  \end{matrix}\right]
$$




我的理解：

1. 既然矩阵微分是对偏导数的布局，那么布局就不能随便布局，就得按照一定规律和顺序把它们排布在结果矩阵上，要么结果矩阵中，对于每一行内的所有元素自变量都相同，因变量按下标顺序从头写按到尾，要么对于每一行内的所有元素因变量都相同，自变量按下标顺序从头写按到尾
2. 如果每一行内的所有元素自变量都相同，因为自变量在分母，所以叫分母布局
3. 如果每一行内的所有元素因变量都相同，因为因变量在分子，所以叫分子布局
4. 如上面的分子布局中，分子只有一个，所以结果只有一行，分子保持不变，分母有n个，所以结果有n列；分母布局中，分母有n个，所以有n行，分子只有一个，所以只有一列
5. 分母布局和分子布局是转置关系，看结果中的每一行每一列是分子不变还是分母不变就知道是啥布局了

更多例子：

![image-20200309205909365](关于矩阵求导的理解\image-20200309205909365.png)

![image-20200309205922941](关于矩阵求导的理解\image-20200309205922941.png)

## 矩阵与标量、标量与矩阵

矩阵参与求导运算，其实就把矩阵拆分成向量组，最后还是再算向量的微分，然后将结果拼在一起。

### 标量对矩阵求导

$$
\frac{\partial y}{\partial\mathbf{X}}=\begin{bmatrix}\frac{\partial y}{\partial x_{11}} & \frac{\partial y}{\partial x_{12}} & \cdots & \frac{\partial y}{\partial x_{1q}}\\
\frac{\partial y}{\partial x_{21}} & \frac{\partial y}{\partial x_{22}} & \cdots & \frac{\partial y}{\partial x_{2q}}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial y}{\partial x_{p1}} & \frac{\partial y}{\partial x_{p2}} & \cdots & \frac{\partial y}{\partial x_{pq}}
\end{bmatrix}
$$

### 矩阵对标量求导

$$
\frac{\partial\mathbf{Y}}{\partial x}=\begin{bmatrix}\frac{\partial y_{11}}{\partial x} & \frac{\partial y_{21}}{\partial x} & \cdots & \frac{\partial y_{m1}}{\partial x}\\
\frac{\partial y_{12}}{\partial x} & \frac{\partial y_{22}}{\partial x} & \cdots & \frac{\partial y_{m2}}{\partial x}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{\partial y_{1n}}{\partial x} & \frac{\partial y_{2n}}{\partial x} & \cdots & \frac{\partial y_{mn}}{\partial x}
\end{bmatrix}
$$

### 矩阵对矩阵求导

将矩阵视为向量组，每个向量组对向量组求导。



## 矩阵求导运算思路与运算法则

### 运算思路：代表元素法

因为无论是矩阵求导，还是向量求导，本质都是每个元素对元素的求导，所以在分析求导问题的时候，可以从结果矩阵中，选取第 $i$ 行 $j$ 列为代表元素，因为代表元素一定是标量的求导，这时可以用熟悉的标量求导法则来推证。

### 代表元素法证明矩阵求导的加减法则

$$
\frac{\partial(\pmb Y+\pmb Z)}{\partial \pmb X}=
\frac{\partial(\pmb Y)}{\partial \pmb X}
+
\frac{\partial(\pmb Z)}{\partial \pmb X}
$$
证明:

假设
$$
\pmb{Z}=(z_1,...,z_n)\\
\pmb{Y}=(y_1,...,y_n)\\
\pmb{X}=(x_1,...,x_n)
$$
由矩阵加法得
$$
\pmb Y+\pmb Z=(y_1+z_1,...,y_n+z_n)\\
\frac{\partial(\pmb Y+\pmb Z)}{\partial \pmb X}=
 \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial( y_i + z_i)}{\partial x_j} &  \\
   &  & 
  \end{matrix}
  \right]\\
 ( y_i + z_i)\in\pmb{Y}+\pmb{Z},x_j\in\pmb{X}\\
 = 
 \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial( y_i)}{\partial x_j}+\frac{\partial( z_i)}{\partial x_j} &  \\
   &  & 
  \end{matrix}
  \right]\\
  y_i\in\pmb{Y},z_i\in\pmb{Z},x_j\in\pmb{X}\\
$$

因为下标 $i$ 和 下标 $j$ 是独立的，所以一定能取遍 $X,Y,Z$ 中所有的分量，故
$$
 \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial( y_i)}{\partial x_j}+\frac{\partial( z_i)}{\partial x_j} &  \\
   &  & 
  \end{matrix}
  \right]
  =
\left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial( y_i)}{\partial x_j} &  \\
   &  & 
  \end{matrix}
  \right]+\left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial( z_i)}{\partial x_j} &  \\
   &  & 
  \end{matrix}
  \right]\\
  y_i\in\pmb{Y},z_i\in\pmb{Z},x_j\in\pmb{X}\\
  =\frac{\partial(\pmb Y)}{\partial \pmb X}
+
\frac{\partial(\pmb Z)}{\partial \pmb X}
$$


### 代表元素法证明乘法法则

$$
\frac{\partial(\pmb Y\cdot\pmb Z)}{\partial \pmb X}=
\frac{\partial(\pmb Y)}{\partial \pmb X}\pmb Z
+
\frac{\partial(\pmb Z)}{\partial \pmb X}\pmb Y
$$

证明：

假设 $X,Y,Z$ 为n维列向量，则
$$
\pmb Y \cdot \pmb Z=\pmb Y ^T \pmb Z=\sum_{i=1}^{n}y_iz_i\\

\frac{\partial\pmb Y\cdot\pmb Z}{\partial \pmb X}=

 \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial(\sum_{i=1}^{n}y_iz_i)}{\partial x_j} &  \\
   &  & 
  \end{matrix}
  \right]\\
 x_j\in\pmb{X}\\
$$


事实上由标量导数的性质和矩阵加法可得， $\sum_{i=1}^{n}y_iz_i$ 的累加符号可以提出去
$$
\left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial(\sum_{i=1}^{n}y_iz_i)}{\partial x_j} &  \\
   &  & 
  \end{matrix}
  \right]
 
=
  \sum_{k=1}^{n}
   \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial(y_kz_k)}{\partial x_j} &  \\
   &  & 
  \end{matrix}
  \right]
  
=
  \sum_{k=1}^{n}
   \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial(y_k)}{\partial x_j}z_k+\frac{\partial(z_k)}{\partial x_j}y_k &  \\
   &  & 
  \end{matrix}
  \right]\\
  
  
  =
  \sum_{k=1}^{n}
   \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial(y_k)}{\partial x_j}z_k &  \\
   &  & 
  \end{matrix}
  \right]
+
 \sum_{k=1}^{n}
   \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial(z_k)}{\partial x_j}y_k &  \\
   &  & 
  \end{matrix}
  \right]\\
   x_j\in\pmb{X}\\
$$
考察第一项，由矩阵加法可得：
$$
\sum_{k=1}^{n}
   \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial(y_k)}{\partial x_j}z_k &  \\
   &  & 
  \end{matrix}
  \right] 
  
  =
    \left[
 \begin{matrix}
    &  &  \\
    &  \sum_{k=1}^{n}\frac{\partial(y_k)}{\partial x_j}z_k &  \\
   &  & 
  \end{matrix}
  \right] \\
  
   x_j\in\pmb{X}\\
$$
方框内的是代表元素，在分母布局下，$x_j$ 的下标 $j$ 表示第 $j$ 行 , 所以该矩阵全貌是
$$
\left[
 \begin{matrix}
    &  &  \\
    &  \sum_{k=1}^{n}\frac{\partial(y_k)}{\partial x_j}z_k &  \\
   &  & 
  \end{matrix}
  \right]
  
  =    
  
  \left[
 \begin{matrix}
     \sum_{k=1}^{n}\frac{\partial(y_k)}{\partial x_1}z_k   \\
    \sum_{k=1}^{n}\frac{\partial(y_k)}{\partial x_2}z_k  \\
   .\\
   .\\
   .\\
    \sum_{k=1}^{n}\frac{\partial(y_k)}{\partial x_n}z_k 
  \end{matrix}
  \right] \\
$$
由
$$
\sum_{i=1}^n a_ib_i

=

[a_1,...,a_n] 
\left[
 \begin{matrix}
   b_1  \\
   .\\
   .\\
   .\\
   b_n
  \end{matrix}
 \right] 
 
$$
很容易判断出
$$
\left[
 \begin{matrix}
     \sum_{k=1}^{n}\frac{\partial(y_k)}{\partial x_1}z_k   \\
    \sum_{k=1}^{n}\frac{\partial(y_k)}{\partial x_2}z_k  \\
   .\\
   .\\
   .\\
    \sum_{k=1}^{n}\frac{\partial(y_k)}{\partial x_n}z_k 
  \end{matrix}
  \right] 
  
  =
  
   \left[
 \begin{matrix}
    \frac{\partial(y_1)}{\partial x_1}&...& \frac{\partial(y_n)}{\partial x_1} \\
   . & & .\\
    . & & .\\
   . & & .\\
    \frac{\partial(y_1)}{\partial x_n}&...& \frac{\partial(y_n)}{\partial x_x}
  \end{matrix}
  \right]

\left[
 \begin{matrix}
   z_1  \\
   .\\
   .\\
   .\\
   z_n
  \end{matrix}
 \right]
 
 =
 
 \frac{\partial(\pmb Y)}{\partial \pmb X}\pmb Z
$$

同理可证，第二项：
$$
\sum_{k=1}^{n}
   \left[
 \begin{matrix}
    &  &  \\
    & \frac{\partial(z_k)}{\partial x_j}y_k &  \\
   &  & 
  \end{matrix}
  \right]=\frac{\partial(\pmb Z)}{\partial \pmb X}\pmb Y\\
$$
此时原式得证
$$
\frac{\partial(\pmb Y\cdot\pmb Z)}{\partial \pmb X}=
\frac{\partial(\pmb Y)}{\partial \pmb X}\pmb Z
+
\frac{\partial(\pmb Z)}{\partial \pmb X}\pmb Y
$$


### 矩阵求导运算法则

其他乘法法则和链式法则也可以用类似的证明思路得到，这里略

![image-20200310171445012](关于矩阵求导的理解\image-20200310171445012.png)

![image-20200310171505597](关于矩阵求导的理解\image-20200310171505597.png)


